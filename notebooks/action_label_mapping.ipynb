# Day 5: Action Label Mapping and Final Inference

import cv2
import numpy as np
import torch
import torchvision
import urllib.request
import os

# -----------------------------
# Step 1: Load Kinetics-400 Labels
# -----------------------------
labels_url = "https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt"
labels_path = "kinetics_labels.txt"

if not os.path.exists(labels_path):
    urllib.request.urlretrieve(labels_url, labels_path)

with open(labels_path, "r") as f:
    labels = [line.strip() for line in f.readlines()]

print("Kinetics-400 labels loaded")

# -----------------------------
# Step 2: Load Pretrained Model
# -----------------------------
model = torchvision.models.video.r3d_18(pretrained=True)
model = model.float()
model.eval()

print("Pretrained R3D-18 model loaded")

# -----------------------------
# Step 3: Video Path
# -----------------------------
# Update this path when running the notebook
video_path = "/content/v_Archery_g01_c02.avi"

cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("Error: Cannot open video")
    exit()

# -----------------------------
# Step 4: Frame Extraction
# -----------------------------
NUM_FRAMES = 16
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

frame_indices = set(
    np.linspace(0, total_frames - 1, NUM_FRAMES, dtype=int)
)

frames = []
current_frame = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    if current_frame in frame_indices:
        frame = cv2.resize(frame, (112, 112))
        frames.append(frame)

    current_frame += 1

cap.release()

if len(frames) != NUM_FRAMES:
    print("Frame extraction failed")
    exit()

print("Frames extracted:", len(frames))

# -----------------------------
# Step 5: Preprocessing
# -----------------------------
frames_np = np.array(frames, dtype=np.float32) / 255.0
frames_tensor = torch.tensor(frames_np)
frames_tensor = frames_tensor.permute(3, 0, 1, 2).unsqueeze(0)

# -----------------------------
# Step 6: Inference
# -----------------------------
with torch.no_grad():
    outputs = model(frames_tensor)
    probabilities = torch.softmax(outputs, dim=1)

predicted_index = probabilities.argmax(dim=1).item()
confidence = probabilities.max().item()
predicted_label = labels[predicted_index]

# -----------------------------
# Step 7: Final Output
# -----------------------------
print("\nPrediction Result")
print("-----------------")
print("Predicted Action:", predicted_label)
print("Confidence Score:", confidence)

if confidence < 0.4:
    print("Note: Low confidence prediction (model uncertain)")

print("Note: Model pretrained on Kinetics-400")

